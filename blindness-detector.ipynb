{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-14T21:47:34.070581Z","iopub.execute_input":"2023-09-14T21:47:34.072116Z","iopub.status.idle":"2023-09-14T21:47:37.650241Z","shell.execute_reply.started":"2023-09-14T21:47:34.072013Z","shell.execute_reply":"2023-09-14T21:47:37.649087Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nimport os\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport cv2\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:58:06.864068Z","iopub.execute_input":"2023-09-14T16:58:06.864589Z","iopub.status.idle":"2023-09-14T16:58:17.772119Z","shell.execute_reply.started":"2023-09-14T16:58:06.864551Z","shell.execute_reply":"2023-09-14T16:58:17.771011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define same parameters\nClass = [\"No DR\", \"Mild\", \"Moderate\", \"Severe\", \"Proliferative DR\"]\nimg_size = 224\n# Define paths to images and labels\ntrain_image_dir = (\n    \"/kaggle/input/aptos2019-blindness-detection/train_images\"\n)\ntrain_label_file = \"/kaggle/input/aptos2019-blindness-detection/train.csv\"","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:47:43.457463Z","iopub.execute_input":"2023-09-14T21:47:43.457963Z","iopub.status.idle":"2023-09-14T21:47:43.464462Z","shell.execute_reply.started":"2023-09-14T21:47:43.457923Z","shell.execute_reply":"2023-09-14T21:47:43.462878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load labels into a pandas dataframe\nlabels_df = pd.read_csv(train_label_file)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:47:44.975213Z","iopub.execute_input":"2023-09-14T21:47:44.976607Z","iopub.status.idle":"2023-09-14T21:47:45.007406Z","shell.execute_reply.started":"2023-09-14T21:47:44.976563Z","shell.execute_reply":"2023-09-14T21:47:45.006532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:58:17.815537Z","iopub.execute_input":"2023-09-14T16:58:17.816487Z","iopub.status.idle":"2023-09-14T16:58:17.842243Z","shell.execute_reply.started":"2023-09-14T16:58:17.816395Z","shell.execute_reply":"2023-09-14T16:58:17.840560Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a dictionary mapping image IDs to labels\nlabel_dict = dict(zip(labels_df[\"id_code\"], labels_df[\"diagnosis\"]))","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:47:47.964355Z","iopub.execute_input":"2023-09-14T21:47:47.965773Z","iopub.status.idle":"2023-09-14T21:47:47.980973Z","shell.execute_reply.started":"2023-09-14T21:47:47.965719Z","shell.execute_reply":"2023-09-14T21:47:47.979442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A dictionary where the keys are the image IDs and the values are the diagnoses\nlabel_dict","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:47:50.052032Z","iopub.execute_input":"2023-09-14T21:47:50.052567Z","iopub.status.idle":"2023-09-14T21:47:50.085657Z","shell.execute_reply.started":"2023-09-14T21:47:50.052527Z","shell.execute_reply":"2023-09-14T21:47:50.084078Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A function to load and preprocess images\ndef load_and_preprocess_image(image_path):\n    image = tf.io.read_file(image_path)\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.image.resize(image, [img_size, img_size])\n    image /= 255.0\n    return image","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:47:55.563094Z","iopub.execute_input":"2023-09-14T21:47:55.563542Z","iopub.status.idle":"2023-09-14T21:47:55.569802Z","shell.execute_reply.started":"2023-09-14T21:47:55.563500Z","shell.execute_reply":"2023-09-14T21:47:55.568694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A function to get the label for an image\ndef get_label(image_path):\n    image_id = os.path.basename(image_path).split(\".\")[0]\n    res = np.zeros(5)\n    res[label_dict[image_id]] = 1\n    return res","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:47:56.682767Z","iopub.execute_input":"2023-09-14T21:47:56.683145Z","iopub.status.idle":"2023-09-14T21:47:56.689026Z","shell.execute_reply.started":"2023-09-14T21:47:56.683116Z","shell.execute_reply":"2023-09-14T21:47:56.687886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_label(\"/kaggle/input/aptos2019-blindness-detection/train_images/ef476be214d4.png\")","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:47:57.501664Z","iopub.execute_input":"2023-09-14T21:47:57.502067Z","iopub.status.idle":"2023-09-14T21:47:57.509810Z","shell.execute_reply.started":"2023-09-14T21:47:57.502035Z","shell.execute_reply":"2023-09-14T21:47:57.508712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# list of image paths\nimage_paths = [\n    os.path.join(train_image_dir, filename) for filename in os.listdir(train_image_dir)\n]","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:47:58.416838Z","iopub.execute_input":"2023-09-14T21:47:58.417228Z","iopub.status.idle":"2023-09-14T21:47:58.434339Z","shell.execute_reply.started":"2023-09-14T21:47:58.417199Z","shell.execute_reply":"2023-09-14T21:47:58.433148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_paths","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:48:00.096387Z","iopub.execute_input":"2023-09-14T21:48:00.096781Z","iopub.status.idle":"2023-09-14T21:48:00.117986Z","shell.execute_reply.started":"2023-09-14T21:48:00.096752Z","shell.execute_reply":"2023-09-14T21:48:00.116829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the dataset into training, validation, and testing sets\ntrain_paths, test_paths, train_labels, test_labels = train_test_split(\n    image_paths,\n    [get_label(path) for path in image_paths],\n    test_size=0.2,\n    random_state=42,\n)\ntrain_paths, val_paths, train_labels, val_labels = train_test_split(\n    train_paths, train_labels, test_size=0.2, random_state=42\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:48:00.817099Z","iopub.execute_input":"2023-09-14T21:48:00.817523Z","iopub.status.idle":"2023-09-14T21:48:00.839357Z","shell.execute_reply.started":"2023-09-14T21:48:00.817489Z","shell.execute_reply":"2023-09-14T21:48:00.838221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a dataset of image paths\ntrain_paths_ds = tf.data.Dataset.from_tensor_slices(train_paths)\nval_paths_ds = tf.data.Dataset.from_tensor_slices(val_paths)\ntest_paths_ds = tf.data.Dataset.from_tensor_slices(test_paths)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:48:01.978773Z","iopub.execute_input":"2023-09-14T21:48:01.979158Z","iopub.status.idle":"2023-09-14T21:48:02.000906Z","shell.execute_reply.started":"2023-09-14T21:48:01.979130Z","shell.execute_reply":"2023-09-14T21:48:01.999708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load and preprocess the images\ntrain_images_ds_1 = train_paths_ds.map(load_and_preprocess_image)\nval_images_ds_1 = val_paths_ds.map(load_and_preprocess_image)\ntest_images_ds_1 = test_paths_ds.map(load_and_preprocess_image)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:48:02.872966Z","iopub.execute_input":"2023-09-14T21:48:02.873363Z","iopub.status.idle":"2023-09-14T21:48:02.936670Z","shell.execute_reply.started":"2023-09-14T21:48:02.873333Z","shell.execute_reply":"2023-09-14T21:48:02.935670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing ","metadata":{}},{"cell_type":"code","source":"# Data Preprocessing (Circular Cropping and Gaussian Blur)\ndef crop_image_from_gray(img, tol=7):\n    if img.ndim == 2:\n        mask = img > tol\n        return img[np.ix_(mask.any(1), mask.any(0))]\n    elif img.ndim == 3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img > tol\n\n        check_shape = img[:, :, 0][np.ix_(mask.any(1), mask.any(0))].shape[0]\n        if check_shape == 0:  # image is too dark so that we crop out everything,\n            return img  # return original image\n        else:\n            img1 = img[:, :, 0][np.ix_(mask.any(1), mask.any(0))]\n            img2 = img[:, :, 1][np.ix_(mask.any(1), mask.any(0))]\n            img3 = img[:, :, 2][np.ix_(mask.any(1), mask.any(0))]\n            img = np.stack([img1, img2, img3], axis=-1)\n        return img\n\n\ndef circle_crop(img, sigmaX):\n    img = img.numpy()\n    img = crop_image_from_gray(img)\n    # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n    height, width, depth = img.shape\n\n    x = int(width / 2)\n    y = int(height / 2)\n    r = np.amin((x, y))\n\n    circle_img = np.zeros((height, width), np.uint8)\n    cv2.circle(circle_img, (x, y), int(r), 1, thickness=-1)\n    img = cv2.bitwise_and(img, img, mask=circle_img)\n    img = crop_image_from_gray(img)\n    img = cv2.addWeighted(img, 4, cv2.GaussianBlur(img, (0, 0), float(sigmaX)), -4, 0.5)\n    return img","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:48:06.068993Z","iopub.execute_input":"2023-09-14T21:48:06.069848Z","iopub.status.idle":"2023-09-14T21:48:06.080887Z","shell.execute_reply.started":"2023-09-14T21:48:06.069813Z","shell.execute_reply":"2023-09-14T21:48:06.079386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# example of Performing Image Processing on an image\nimg = list(train_images_ds_1.take(1))[0]\nimg_t = circle_crop(img, sigmaX=30)\n\nf, axarr = plt.subplots(1, 2, figsize=(11, 11))\naxarr[0].imshow(img)\naxarr[1].imshow(img_t)\nplt.title(\"After applying Circular Crop and Gaussian Blur\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:48:06.164435Z","iopub.execute_input":"2023-09-14T21:48:06.164873Z","iopub.status.idle":"2023-09-14T21:48:07.138615Z","shell.execute_reply.started":"2023-09-14T21:48:06.164838Z","shell.execute_reply":"2023-09-14T21:48:07.137575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply the function over the dataset\ntrain_images_ds = train_images_ds_1.map(\n    lambda x: tf.py_function(circle_crop, [x, 30], tf.float32)\n)\nval_images_ds = val_images_ds_1.map(\n    lambda x: tf.py_function(circle_crop, [x, 30], tf.float32)\n)\ntest_images_ds = test_images_ds_1.map(\n    lambda x: tf.py_function(circle_crop, [x, 30], tf.float32)\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:48:07.140320Z","iopub.execute_input":"2023-09-14T21:48:07.140668Z","iopub.status.idle":"2023-09-14T21:48:07.181279Z","shell.execute_reply.started":"2023-09-14T21:48:07.140637Z","shell.execute_reply":"2023-09-14T21:48:07.180297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Combine the images and labels into a single dataset\ntrain = tf.data.Dataset.zip(\n    (train_images_ds, tf.data.Dataset.from_tensor_slices(train_labels))\n)\nval = tf.data.Dataset.zip(\n    (val_images_ds, tf.data.Dataset.from_tensor_slices(val_labels))\n)\ntest = tf.data.Dataset.zip(\n    (test_images_ds, tf.data.Dataset.from_tensor_slices(test_labels))\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:48:07.543769Z","iopub.execute_input":"2023-09-14T21:48:07.544821Z","iopub.status.idle":"2023-09-14T21:48:07.620245Z","shell.execute_reply.started":"2023-09-14T21:48:07.544779Z","shell.execute_reply":"2023-09-14T21:48:07.619109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.batch(8)\ntrain = train.prefetch(4)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:48:07.943324Z","iopub.execute_input":"2023-09-14T21:48:07.944244Z","iopub.status.idle":"2023-09-14T21:48:07.950817Z","shell.execute_reply.started":"2023-09-14T21:48:07.944203Z","shell.execute_reply":"2023-09-14T21:48:07.949764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test.batch(8)\ntest = test.prefetch(4)\nval = val.batch(8)\nval = val.prefetch(4)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:48:08.895116Z","iopub.execute_input":"2023-09-14T21:48:08.895562Z","iopub.status.idle":"2023-09-14T21:48:08.903838Z","shell.execute_reply.started":"2023-09-14T21:48:08.895525Z","shell.execute_reply":"2023-09-14T21:48:08.902545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.as_numpy_iterator().next()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:48:09.554299Z","iopub.execute_input":"2023-09-14T21:48:09.554734Z","iopub.status.idle":"2023-09-14T21:48:10.115543Z","shell.execute_reply.started":"2023-09-14T21:48:09.554687Z","shell.execute_reply":"2023-09-14T21:48:10.114235Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming the train_dataset is already loaded\nfig, axs = plt.subplots(2, 2, figsize=(10, 10))\naxs = axs.flatten()\ntrain_plot = train.take(4)\nfor (img, label), ax in zip(train_plot, axs):\n    ax.imshow(img.numpy()[0])\n    ax.set_title(f\"Label: {label.numpy()[0]}\")\n    ax.axis(\"off\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:48:10.159594Z","iopub.execute_input":"2023-09-14T21:48:10.160015Z","iopub.status.idle":"2023-09-14T21:48:13.556798Z","shell.execute_reply.started":"2023-09-14T21:48:10.159983Z","shell.execute_reply":"2023-09-14T21:48:13.555413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building the Model","metadata":{}},{"cell_type":"code","source":"LEARNING_RATE = 1e-4\nWARMUP_LEARNING_RATE = 1e-3\nWARMUP_EPOCHS = 3","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:48:13.558943Z","iopub.execute_input":"2023-09-14T21:48:13.559279Z","iopub.status.idle":"2023-09-14T21:48:13.564624Z","shell.execute_reply.started":"2023-09-14T21:48:13.559252Z","shell.execute_reply":"2023-09-14T21:48:13.563467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:58:23.445655Z","iopub.execute_input":"2023-09-14T16:58:23.446132Z","iopub.status.idle":"2023-09-14T16:58:23.466692Z","shell.execute_reply.started":"2023-09-14T16:58:23.446103Z","shell.execute_reply":"2023-09-14T16:58:23.465388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model():\n    # Load the pre-trained ResNet50 model\n    base_model = ResNet50(\n        weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3)\n    )\n\n    # Add a global average pooling layer\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n\n    # Add a fully connected layer with 2048 neurons and ReLU activation\n    x = Dense(2048, activation=\"relu\")(x)\n\n    # Dropout by 0.5\n    x = Dropout(0.5)(x)\n\n    # Add an output layer with 5 neurons (for the 5 classes) and softmax activation\n    predictions = Dense(5, activation=\"softmax\")(x)\n\n    # Create the final model\n    model = Model(inputs=base_model.input, outputs=predictions)\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:58:23.467992Z","iopub.execute_input":"2023-09-14T16:58:23.468576Z","iopub.status.idle":"2023-09-14T16:58:23.482395Z","shell.execute_reply.started":"2023-09-14T16:58:23.468540Z","shell.execute_reply":"2023-09-14T16:58:23.481465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = create_model()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:58:23.483665Z","iopub.execute_input":"2023-09-14T16:58:23.484166Z","iopub.status.idle":"2023-09-14T16:58:26.558317Z","shell.execute_reply.started":"2023-09-14T16:58:23.484136Z","shell.execute_reply":"2023-09-14T16:58:26.557120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for layer in model.layers:\n    layer.trainable = False\n\nfor i in range(-5, 0):\n    model.layers[i].trainable = True","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:58:26.564890Z","iopub.execute_input":"2023-09-14T16:58:26.565265Z","iopub.status.idle":"2023-09-14T16:58:26.578312Z","shell.execute_reply.started":"2023-09-14T16:58:26.565234Z","shell.execute_reply":"2023-09-14T16:58:26.577107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:58:26.579660Z","iopub.execute_input":"2023-09-14T16:58:26.580014Z","iopub.status.idle":"2023-09-14T16:58:27.083350Z","shell.execute_reply.started":"2023-09-14T16:58:26.579983Z","shell.execute_reply":"2023-09-14T16:58:27.077654Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# see the model architecture\ntf.keras.utils.plot_model(model)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:58:27.088901Z","iopub.execute_input":"2023-09-14T16:58:27.089329Z","iopub.status.idle":"2023-09-14T16:58:28.907596Z","shell.execute_reply.started":"2023-09-14T16:58:27.089297Z","shell.execute_reply":"2023-09-14T16:58:28.906273Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  **Training the Model**","metadata":{}},{"cell_type":"code","source":"# Warm up the model to make our new layers get some initial training\nmodel.compile(\n    optimizer=optimizers.Adam(lr=WARMUP_LEARNING_RATE),\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"],\n)\n\nhistory_warmup = model.fit(train, validation_data=val, epochs=WARMUP_EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:58:28.908870Z","iopub.execute_input":"2023-09-14T16:58:28.909237Z","iopub.status.idle":"2023-09-14T17:17:23.763663Z","shell.execute_reply.started":"2023-09-14T16:58:28.909206Z","shell.execute_reply":"2023-09-14T17:17:23.760479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# now make all layers trainable\nfor layer in model.layers:\n    layer.trainable = True","metadata":{"execution":{"iopub.status.busy":"2023-09-14T17:17:23.771978Z","iopub.execute_input":"2023-09-14T17:17:23.773547Z","iopub.status.idle":"2023-09-14T17:17:23.790666Z","shell.execute_reply.started":"2023-09-14T17:17:23.773435Z","shell.execute_reply":"2023-09-14T17:17:23.789347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"es = EarlyStopping(\n    monitor=\"val_loss\", mode=\"min\", patience=5, restore_best_weights=True, verbose=1\n)\nrlrop = ReduceLROnPlateau(\n    monitor=\"val_loss\", mode=\"min\", patience=3, factor=0.5, min_lr=1e-6, verbose=1\n)\n\ncallback_list = [es, rlrop]\noptimizer = optimizers.Adam(lr=LEARNING_RATE)\nmodel.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T17:17:23.792965Z","iopub.execute_input":"2023-09-14T17:17:23.793536Z","iopub.status.idle":"2023-09-14T17:17:24.436816Z","shell.execute_reply.started":"2023-09-14T17:17:23.793483Z","shell.execute_reply":"2023-09-14T17:17:24.435561Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_finetunning = model.fit(\n    train, validation_data=val, epochs=40, callbacks=callback_list, verbose=1\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T17:17:24.438574Z","iopub.execute_input":"2023-09-14T17:17:24.438942Z","iopub.status.idle":"2023-09-14T21:12:50.640505Z","shell.execute_reply.started":"2023-09-14T17:17:24.438910Z","shell.execute_reply":"2023-09-14T21:12:50.636667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 5))\n\nplt.plot(history_finetunning.history[\"accuracy\"])\nplt.plot(history_finetunning.history[\"val_accuracy\"])\nplt.title(\"Model Accuracy\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"Train\", \"Validation\"], loc=\"upper left\")\nplt.gca().ticklabel_format(axis=\"both\", style=\"plain\", useOffset=False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:12:50.646438Z","iopub.execute_input":"2023-09-14T21:12:50.647962Z","iopub.status.idle":"2023-09-14T21:13:03.973786Z","shell.execute_reply.started":"2023-09-14T21:12:50.647906Z","shell.execute_reply":"2023-09-14T21:13:03.970164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"CodeClauseInternship_blindnessdetection.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:13:03.978332Z","iopub.execute_input":"2023-09-14T21:13:03.982306Z","iopub.status.idle":"2023-09-14T21:13:06.641910Z","shell.execute_reply.started":"2023-09-14T21:13:03.982114Z","shell.execute_reply":"2023-09-14T21:13:06.637013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loading the model later\nfrom tensorflow.keras.models import load_model\n\nmodel = load_model(\"CodeClauseInternship_blindnessdetection.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:13:06.647259Z","iopub.execute_input":"2023-09-14T21:13:06.648036Z","iopub.status.idle":"2023-09-14T21:13:10.523031Z","shell.execute_reply.started":"2023-09-14T21:13:06.647987Z","shell.execute_reply":"2023-09-14T21:13:10.521725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_iter = test.as_numpy_iterator()\ntest_plot = test_iter.next()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:48:50.403423Z","iopub.execute_input":"2023-09-14T21:48:50.403834Z","iopub.status.idle":"2023-09-14T21:48:50.887819Z","shell.execute_reply.started":"2023-09-14T21:48:50.403803Z","shell.execute_reply":"2023-09-14T21:48:50.886551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_plot","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:50:20.643006Z","iopub.execute_input":"2023-09-14T21:50:20.643796Z","iopub.status.idle":"2023-09-14T21:50:20.659267Z","shell.execute_reply.started":"2023-09-14T21:50:20.643755Z","shell.execute_reply":"2023-09-14T21:50:20.657886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = model.predict(test_plot[0])","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:50:08.844216Z","iopub.execute_input":"2023-09-14T21:50:08.844709Z","iopub.status.idle":"2023-09-14T21:50:09.580121Z","shell.execute_reply.started":"2023-09-14T21:50:08.844671Z","shell.execute_reply":"2023-09-14T21:50:09.579187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:49:01.518404Z","iopub.execute_input":"2023-09-14T21:49:01.519199Z","iopub.status.idle":"2023-09-14T21:49:01.528960Z","shell.execute_reply.started":"2023-09-14T21:49:01.519160Z","shell.execute_reply":"2023-09-14T21:49:01.526808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(4, 2, figsize=(10, 10))\nplt.subplots_adjust(wspace=0.4, hspace=0.4)\naxs = axs.flatten()\nfor n, ax in enumerate(axs):\n    ax.imshow(test_plot[0][n])\n    ax.set_title(\n        f\"\"\"Predicted Label: {Class[np.argmax(pred[n])]}\n    Actual label: {Class[np.argmax(test_plot[1][n])]}\"\"\"\n    )\n    ax.axis(\"off\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T21:49:07.551822Z","iopub.execute_input":"2023-09-14T21:49:07.554288Z","iopub.status.idle":"2023-09-14T21:49:09.294134Z","shell.execute_reply.started":"2023-09-14T21:49:07.554240Z","shell.execute_reply":"2023-09-14T21:49:09.291684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}